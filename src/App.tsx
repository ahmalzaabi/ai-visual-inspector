import { useState, useRef, useCallback, useEffect } from 'react'
import './App.css'
import HandGestureTracker from './components/HandGestureTracker'
import AROverlay from './components/AROverlay'

function App() {
  const [isPlaying, setIsPlaying] = useState(false)
  const [capturedImage, setCapturedImage] = useState<string | null>(null)
  const [error, setError] = useState<string | null>(null)
  const [isGestureMode, setIsGestureMode] = useState(false)
  const [fingerCount, setFingerCount] = useState(0)
  const [handLandmarks, setHandLandmarks] = useState<any[]>([])
  const [debugInfo, setDebugInfo] = useState<string>('')
  const videoRef = useRef<HTMLVideoElement>(null)
  const canvasRef = useRef<HTMLCanvasElement>(null)

  const startCamera = useCallback(async () => {
    try {
      setError(null)
      setDebugInfo('ğŸ”„ Starting camera...')
      
      // Check if getUserMedia is supported
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('Camera API not supported in this browser')
      }

      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: 'environment',
          width: { ideal: 1280 },
          height: { ideal: 720 }
        }
      })
      
      console.log('ğŸ“¹ Stream obtained:', stream.active, stream.getVideoTracks().length)
      setDebugInfo('âœ… Camera access granted')
      
      if (videoRef.current) {
        // Stop any existing stream
        if (videoRef.current.srcObject) {
          const oldStream = videoRef.current.srcObject as MediaStream
          oldStream.getTracks().forEach(track => track.stop())
        }
        
        // Assign the new stream
        videoRef.current.srcObject = stream
        console.log('ğŸ¬ Setting isPlaying to true...')
        setIsPlaying(true) // Set immediately when stream is assigned
        console.log('ğŸ¬ isPlaying state updated')
        
        // Force re-render check
        setTimeout(() => {
          console.log('ğŸ” State check - isPlaying:', isPlaying)
          if (!isPlaying) {
            console.log('âš ï¸ isPlaying is still false, forcing update...')
            setIsPlaying(true)
          }
        }, 100)
        
        // Set up event handlers
        videoRef.current.onloadedmetadata = () => {
          console.log('ğŸ“¹ Video metadata loaded:', videoRef.current?.videoWidth, 'x', videoRef.current?.videoHeight)
          setDebugInfo(`ğŸ“¹ Video ready: ${videoRef.current?.videoWidth}x${videoRef.current?.videoHeight}`)
        }
        
        videoRef.current.onplay = () => {
          console.log('â–¶ï¸ Video playing')
          setDebugInfo('â–¶ï¸ Video playing')
        }
        
        videoRef.current.oncanplay = () => {
          console.log('âœ… Video can play')
          setDebugInfo('âœ… Video ready to play')
        }
        
        videoRef.current.onerror = (e) => {
          console.error('Video error:', e)
          setDebugInfo('âŒ Video error occurred')
        }
        
        // Force play the video
        try {
          await videoRef.current.play()
          setDebugInfo('âœ… Video started successfully')
        } catch (playError) {
          console.warn('Auto-play failed, but video should still be visible:', playError)
          setDebugInfo('âš ï¸ Video ready (click to play if needed)')
        }
        
        // Debug info about video element
        setTimeout(() => {
          if (videoRef.current) {
            const video = videoRef.current
            console.log('ğŸ” Video element debug:', {
              srcObject: !!video.srcObject,
              videoWidth: video.videoWidth,
              videoHeight: video.videoHeight,
              readyState: video.readyState,
              paused: video.paused,
              ended: video.ended,
              muted: video.muted,
              autoplay: video.autoplay
            })
          }
        }, 2000)
      }
    } catch (err: any) {
      console.error('Camera error:', err)
      setError(`Camera Error: ${err.message}`)
      setDebugInfo(`âŒ ${err.message}`)
    }
  }, [])

  const stopCamera = useCallback(() => {
    if (videoRef.current?.srcObject) {
      const stream = videoRef.current.srcObject as MediaStream
      stream.getTracks().forEach(track => track.stop())
      videoRef.current.srcObject = null
      setIsPlaying(false)
      setIsGestureMode(false)
      setDebugInfo('â¹ï¸ Camera stopped')
    }
  }, [])

  const capturePhoto = useCallback(() => {
    if (videoRef.current && canvasRef.current) {
      const video = videoRef.current
      const canvas = canvasRef.current
      const context = canvas.getContext('2d')
      
      if (context) {
        canvas.width = video.videoWidth
        canvas.height = video.videoHeight
        context.drawImage(video, 0, 0)
        
        const imageData = canvas.toDataURL('image/jpeg', 0.8)
        setCapturedImage(imageData)
        setDebugInfo('ğŸ“¸ Photo captured successfully')
      }
    }
  }, [])

  const clearCapture = useCallback(() => {
    setCapturedImage(null)
  }, [])

  const toggleGestureMode = useCallback(() => {
    const newMode = !isGestureMode
    setIsGestureMode(newMode)
    if (newMode) {
      setCapturedImage(null)
      setDebugInfo('ğŸ–ï¸ Gesture mode activated')
    } else {
      setDebugInfo('ğŸ“· Photo mode activated')
    }
  }, [isGestureMode])

  const handleGestureDetected = useCallback((count: number, landmarks: any[]) => {
    setFingerCount(count)
    setHandLandmarks(landmarks)
  }, [])

  return (
    <div className="app">
      <header className="app-header">
        <h1>ğŸ” AI Visual Inspector v1.0</h1>
        <p>Capture and analyze images with AI â€¢ AR Gestures âœ¨</p>
        {isPlaying && (
          <div className="mode-toggle">
            <button 
              className={`btn ${isGestureMode ? 'btn-success' : 'btn-secondary'}`}
              onClick={toggleGestureMode}
            >
              {isGestureMode ? 'ğŸ–ï¸ Gesture Mode ON' : 'ğŸ“· Photo Mode'}
            </button>
          </div>
        )}
      </header>

      <main className="app-main">
        {error && (
          <div className="error-message">
            âš ï¸ {error}
          </div>
        )}

        {debugInfo && (
          <div className="debug-info">
            â„¹ï¸ {debugInfo}
            <br />
            <small>isPlaying: {isPlaying ? 'âœ…' : 'âŒ'} | Video Ref: {videoRef.current ? 'âœ…' : 'âŒ'}</small>
          </div>
        )}

        <div className="camera-container">
          {!isPlaying ? (
            <div className="camera-placeholder">
              <div className="camera-icon">ğŸ“·</div>
              <p>Camera not active</p>
              <p style={{ fontSize: '0.8rem', opacity: 0.7 }}>
                Make sure to allow camera permissions
              </p>
              <button 
                className="btn btn-primary" 
                onClick={startCamera}
              >
                Start Camera
              </button>
            </div>
          ) : null}
          
          {/* Always render video element, but hide when not playing */}
          <div 
            className="camera-active"
            style={{ 
              display: isPlaying ? 'flex' : 'none',
              width: '100%',
              flexDirection: 'column',
              gap: '1rem'
            }}
          >
            <div className="video-container">
              <video 
                ref={videoRef}
                autoPlay
                playsInline
                muted
                className="video-feed"
                style={{
                  width: '100%',
                  height: 'auto',
                  minHeight: '300px',
                  backgroundColor: '#000',
                  borderRadius: '12px',
                  border: '3px solid lime', // Visible border to see video element
                  display: 'block'
                }}
                onClick={() => {
                  // Allow user to manually start video if autoplay fails
                  if (videoRef.current) {
                    videoRef.current.play().catch(console.warn)
                  }
                }}
              />
              
              {/* Video Debug Info Overlay */}
              <div style={{
                position: 'absolute',
                top: '10px',
                left: '10px',
                background: 'rgba(0,0,0,0.8)',
                color: 'white',
                padding: '0.5rem',
                borderRadius: '4px',
                fontSize: '0.8rem',
                zIndex: 50
              }}>
                Video: {videoRef.current?.videoWidth || 0}x{videoRef.current?.videoHeight || 0}
                <br />
                State: {videoRef.current?.readyState || 0} | Paused: {videoRef.current?.paused ? 'Yes' : 'No'}
                <br />
                Stream: {videoRef.current?.srcObject ? 'Yes' : 'No'}
              </div>
              
              {/* Hand Gesture Tracking Overlay */}
              {isGestureMode && (
                <HandGestureTracker
                  videoRef={videoRef}
                  onGestureDetected={handleGestureDetected}
                  isActive={isGestureMode}
                />
              )}
              
              {/* AR Elements Overlay */}
              {isGestureMode && (
                <AROverlay
                  fingerCount={fingerCount}
                  handLandmarks={handLandmarks}
                  isActive={isGestureMode}
                />
              )}

              {/* Gesture Info Display */}
              {isGestureMode && (
                <div className="gesture-info">
                  <div className="finger-count-display">
                    <span className="finger-count">{fingerCount}</span>
                    <span className="finger-label">
                      {fingerCount === 0 ? 'Show fingers' : 
                       fingerCount === 1 ? 'â­ Star!' :
                       fingerCount === 2 ? 'ğŸ§Š Cubes!' :
                       fingerCount === 3 ? 'âšª Spheres!' :
                       fingerCount === 4 ? 'ğŸ”º Pyramids!' :
                       fingerCount === 5 ? 'â¤ï¸ Hearts!' : 'Too many!'}
                    </span>
                  </div>
                </div>
              )}
            </div>
            
            <div className="camera-controls">
              {!isGestureMode ? (
                <button 
                  className="btn btn-capture" 
                  onClick={capturePhoto}
                >
                  ğŸ“¸ Capture
                </button>
              ) : (
                <div className="gesture-instructions">
                  <p>ğŸ–ï¸ Show 1-5 fingers to see AR elements!</p>
                </div>
              )}
              <button 
                className="btn btn-secondary" 
                onClick={stopCamera}
              >
                Stop Camera
              </button>
            </div>
          </div>
        </div>

        {capturedImage && !isGestureMode && (
          <div className="captured-image-container">
            <h3>ğŸ“¸ Captured Image</h3>
            <img 
              src={capturedImage} 
              alt="Captured" 
              className="captured-image"
            />
            <div className="image-actions">
              <button 
                className="btn btn-success"
                onClick={() => alert('AI Analysis would happen here!')}
              >
                ğŸ¤– Analyze with AI
              </button>
              <button 
                className="btn btn-secondary" 
                onClick={clearCapture}
              >
                ğŸ—‘ï¸ Clear
              </button>
            </div>
          </div>
        )}

        <canvas ref={canvasRef} style={{ display: 'none' }} />
      </main>

      <footer className="app-footer">
        <p>PWA ready â€¢ Works offline â€¢ Mobile optimized â€¢ AR Gestures âœ¨</p>
      </footer>
    </div>
  )
}

export default App
